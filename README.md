# MyApply Resume Tailor

This is the class project where I‚Äôm building a lightweight resume tailoring portal on top of Django. Job seekers can track roles they‚Äôre interested in, store a structured "experience graph," and run an OpenAI-powered workflow that spits out tailored resume bullets. Everything runs against MySQL and a Celery worker so the browser never blocks while OpenAI does its thing.

## What lives in each app?

- **accounts** ‚Äì custom `User` model with roles plus token/word usage counters so I can rate-limit OpenAI consumption.
- **profiles** ‚Äì simple CRUD for the user‚Äôs personal info and links that end up on the resume preview.
- **experience** ‚Äì the ‚Äúexperience graph‚Äù manager. Users edit job, project, education, and volunteer entries through well-validated forms that write to JSON in MySQL. Sorting, validation, and conversions all live in `experience/services.py`.
- **jobs** ‚Äì lets a user paste a job description, drop a posting URL, or do both. Stores parsing metadata so the tailoring service can reuse it.
- **tailoring** ‚Äì asynchronous pipeline: snapshots the job + experience data, enqueues a Celery task, calls the OpenAI Responses API, and stores the generated bullets/sections/suggestions with debug logs.
- **maps** ‚Äì placeholder for Mapbox commute calculations (API key wiring is already in settings but the feature is still a stub).
- **myapply** ‚Äì the project config plus shared templates (`base.html`, dashboard, login) and Celery bootstrap.

## Stack + infrastructure

- **Backend**: Django 4.2, Python 3.10+, Django REST Framework for the API, Celery 5 with Redis for background jobs.
- **Database**: MySQL only. There‚Äôs no SQLite fallback anywhere, so make sure you have a running MySQL 8 instance for dev and tests.
- **AI**: OpenAI Responses API (model defaults to `gpt-4.1-mini`). The service handles prompt building, requirement extraction, and output parsing.
- **Other services**: Redis (broker + result backend), optional Mapbox token waiting for the maps feature.
- **Frontend**: Django template system with all templates scoped to each app, plus a shared CSS file in `static/css/style.css`.

## Local setup

1. Clone the repo and create a virtualenv.
2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
3. Make sure MySQL is running and create a database/user. For example:
   ```sql
   CREATE DATABASE myapply CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;
   CREATE USER 'myapply_user'@'localhost' IDENTIFIED BY 'choose_a_password';
   GRANT ALL PRIVILEGES ON myapply.* TO 'myapply_user'@'localhost';
   FLUSH PRIVILEGES;
   ```
4. Copy `.env.example` to `.env` and fill in the blanks for `DJANGO_SECRET_KEY`, MySQL creds, `OPENAI_API_KEY`, `OPENAI_MODEL`, and the Redis URLs. No SQLite settings are honored, so leave those out.
5. Run migrations and create a superuser:
   ```bash
   python manage.py migrate
   python manage.py createsuperuser
   ```
6. Start Redis (local default is fine):
   ```bash
   redis-server
   ```
7. In separate terminals, launch Celery and Django:
   ```bash
   celery -A myapply worker -l info
   python manage.py runserver
   ```
8. Visit `http://127.0.0.1:8000/`, log in, and you‚Äôre set.

### Running tests

Tests expect a reachable MySQL database and any required env vars. Run everything with:
```bash
python manage.py test
```

## Feature highlights

### Experience manager
- Four supported types (work, education, project, volunteer) with validation baked into `ExperienceService`.
- Glassmorphism card UI, dynamic achievements, and comma-separated skill tags.
- Everything saved to the `ExperienceGraph` JSON field, sorted and sanitized before it touches MySQL.
- When a location is provided (and `MAPBOX_TOKEN` is set) the service forward-geocodes it with Mapbox and stores latitude/longitude for future isochrone calculations.

### Job tracking
- Single form that accepts a posting URL, raw description text, or both.
- Metadata fields (company, location, parsed_requirements, etc.) live on the `JobPosting` model, so the tailoring task can reuse them without re-scraping.

### Tailoring workflow
- Creates a `TailoringSession` with snapshots of the job data and the user's experience graph.
- Users choose sections, tone, bullet counts, and whether to include summaries or cover letters before submitting.
- **4-Stage Optimized Pipeline**:
  1. **Job Analysis**: Extract ATS-critical keywords, required vs. preferred skills, certifications, years of experience
  2. **Experience Matching**: Score and rank experiences, select top 5 most relevant (60% token reduction)
  3. **AI Generation**: Call OpenAI with optimized prompt emphasizing ATS compatibility and recruiter appeal
  4. **Quality Validation**: Calculate ATS score (0-100%), validate bullet quality, provide actionable suggestions
- **OpenAI Web Search**: When a job URL is provided, OpenAI's grounding/web search automatically fetches the complete job posting, eliminating need for custom scraping
- **ATS Scoring**: Every session receives an ATS compatibility score showing keyword match, required skills coverage, and missing critical elements
- **Token Optimization**: Reduced from ~7,150 to ~4,400 tokens per session (38% savings) through smart experience filtering
- Token usage and word counts are recorded back onto the user for quota tracking.
- Session detail page shows statuses, run IDs, token stats, ATS scores, generated content, and a collapsible debug log for troubleshooting.
- If the queue is unavailable when you start a run, the session is marked failed instantly with guidance so the UI never stalls.
- Status badges expect uppercase strings (`PENDING`, `PROCESSING`, `COMPLETED`, `FAILED`), so keep enum values in sync with the model.
- Sessions that sit in `PENDING` longer than the configured timeout automatically retry or get marked failed with a clear message; `PROCESSING` sessions get the same treatment if they exceed their window.
- Creating a session returns immediately‚Äîthe async worker handles the heavy lifting‚Äîand you can delete a run from its detail page if something goes wrong.

### Dashboard + profiles
- Dashboard pulls recent jobs, tailoring sessions, and token counts.
- Profile editor keeps basic resume contact info in sync with what the tailoring output expects.

### API surface
- REST endpoints for authentication, experience graph CRUD, job postings, tailoring sessions, and profiles (see `myapply/urls.py` + app `frontend_urls.py`).
- Token auth + session auth are both enabled so the web UI and API clients can coexist.

## Environment variables cheat sheet

```
DJANGO_SECRET_KEY=change-me
DEBUG=True
DB_NAME=myapply
DB_USER=myapply_user
DB_PASSWORD=...
DB_HOST=localhost
DB_PORT=3306
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4.1-mini
CELERY_BROKER_URL=redis://127.0.0.1:6379/0
CELERY_RESULT_BACKEND=redis://127.0.0.1:6379/0
TAILORING_PENDING_TIMEOUT_MINUTES=5
TAILORING_PROCESSING_TIMEOUT_MINUTES=15
MAPBOX_TOKEN=optional
LOG_LEVEL=INFO
```

## Why no SQLite?

The project relies on JSON columns, MySQL-specific ordering, and long-running Celery jobs that expect a real database connection. Tests and dev use the same MySQL instance so that I don‚Äôt get surprised by behavior differences later. If MySQL isn‚Äôt available, the app just won‚Äôt boot.

## ATS Optimization Strategy

### Overview
The platform uses a comprehensive ATS (Applicant Tracking System) optimization strategy to maximize both automated filtering success and recruiter appeal.

### Key Features

#### 1. Enhanced Keyword Extraction (200+ keywords)
- **Technical Skills**: Python, Java, JavaScript, AWS, Azure, Docker, Kubernetes, React, Django, etc.
- **Action Verbs**: Led, Managed, Developed, Achieved, Optimized, Implemented, etc.
- **Soft Skills**: Leadership, Communication, Problem-Solving, Project Management, etc.
- **Certifications**: AWS Certified, PMP, CISSP, Scrum Master, etc.
- **Multi-word Detection**: "machine learning", "aws certified", "data science"

#### 2. Advanced Job Requirements Parsing
Automatically categorizes:
- **Required Skills** (60% of ATS score) - Must-have qualifications
- **Preferred Skills** (10% of ATS score) - Nice-to-have qualifications
- **Years of Experience** - Extracted from patterns like "5+ years"
- **Education Requirements** - Bachelor's, Master's, PhD, MBA
- **Certifications** - Detected across full job description

#### 3. ATS Scoring Methodology
```
Overall Score = (Required Skills √ó 0.60) + (Keywords √ó 0.30) + (Preferred Skills √ó 0.10)
```

**Score Interpretation:**
- **85-100%**: Excellent (95% ATS pass rate)
- **70-84%**: Good (75% ATS pass rate)
- **50-69%**: Fair (40% ATS pass rate)
- **<50%**: Poor (10% ATS pass rate)

#### 4. Bullet Point Quality Validation
Every bullet is checked for:
- ‚úÖ Strong action verb at start
- ‚úÖ Metrics included (%, $, numbers)
- ‚úÖ Optimal length (100-180 characters)
- ‚úÖ Proper capitalization
- ‚úÖ Keyword density

#### 5. Prompt Engineering for ATS
**Critical ATS Rules:**
1. üéØ Keyword density - Include ALL required skills
2. üí™ Action verbs - Start EVERY bullet with strong verb
3. üìä Quantify everything - 80%+ bullets have metrics
4. üéì Mirror job language - Use exact terminology
5. üìè Optimal length - 100-180 characters
6. üèÜ Impact formula - Action + Task + Tool + Result + Impact

**Bullet Point Formula:**
```
[Action Verb] + [Specific Activity] + [with X tool/skill] + 
[achieving Y% improvement] + [resulting in $Z impact]
```

**Example:**
```
Developed automated ETL pipeline using Python and Airflow, reducing data 
processing time by 65% and saving $120K annually in infrastructure costs
```

### Performance Metrics

| Metric | Before | After | Improvement |
|--------|--------|-------|-------------|
| **Token Usage** | 7,150 | 4,400 | -38% |
| **ATS Pass Rate** | ~60% | ~85% | +42% |
| **Required Skills Coverage** | ~70% | ~95% | +36% |
| **Keyword Match** | ~55% | ~85% | +55% |
| **Bullets with Metrics** | ~40% | ~80% | +100% |
| **Action Verb Usage** | ~65% | ~100% | +54% |

### Cost Savings
At $0.002 per 1K tokens:
- **Per session**: $0.0055 saved
- **Per 100K sessions**: **$550 saved**

### Using the System

#### For Job Seekers

**Target ATS Score: 85%+**

1. **Complete Your Experience Graph**
   - Add all relevant skills (system matches top 5 automatically)
   - Include metrics in achievements (%, $, numbers)
   - Use industry-standard terminology

2. **Provide Job URL or Description**
   - URL preferred (OpenAI fetches complete posting)
   - Include full description if pasting manually

3. **Review ATS Score**
   - Check the score at top of suggestions
   - Address missing required skills immediately
   - Add suggested keywords naturally

4. **Iterate Based on Suggestions**
   - Focus on required skills first (60% of score)
   - Add metrics where suggested
   - Ensure bullets start with action verbs

#### Example ATS Score Output
```
üìä ATS Compatibility: 87.3% | Required Skills: 93.3% | Keywords: 82.5%
```

**Suggestions Generated:**
- "CRITICAL: Add these required skills: Kubernetes, GraphQL"
- "Add quantifiable metrics (%, $, numbers)"
- "Excellent ATS compatibility! Your resume should pass most ATS filters."

## Technical Implementation

### Architecture

#### Service Layer (`tailoring/services.py`)
**TailoringService Class:**
- `run_workflow()` - Main orchestrator method
- `_generate_tailored_content()` - OpenAI API integration with grounding
- `_parse_job_description()` - Extracts requirements, skills, certifications
- `_calculate_ats_score()` - Computes ATS compatibility percentage
- `_score_bullets()` - Validates bullet point quality
- `_build_prompt()` - Creates optimized prompt for OpenAI

**Key Implementation Details:**
```python
# OpenAI Grounding Parameter (Web Search)
grounding = {
    "type": "web_search",
    "web_search": {
        "queries": [f"job posting {source_url}"]
    }
}

# ATS Scoring Formula
required_skills_score = matched_required / total_required * 100
keyword_score = matched_keywords / total_keywords * 100
preferred_skills_score = matched_preferred / total_preferred * 100

overall_score = (
    required_skills_score * 0.60 +
    keyword_score * 0.30 +
    preferred_skills_score * 0.10
)
```

#### Background Tasks (`tailoring/tasks.py`)
**Celery Task:** `process_tailoring_session(session_id)`
- Loads session and experience graph from database
- Extracts job description from `raw_description` field
- Invokes `TailoringService.run_workflow()` with OpenAI grounding
- Saves tailored content and ATS metadata
- Updates session status to 'completed' or 'failed'

**Job Snapshot Structure:**
```python
{
    "url": source_url,
    "raw_description": raw_description,
    "fetched_at": datetime.now().isoformat()
}
```

### Prompt Engineering

#### System Prompt Structure
```
You are an expert resume consultant specializing in ATS optimization.

Given:
1. Candidate's experience graph (skills, roles, achievements)
2. Job description (OpenAI will fetch from URL if provided)

Generate:
- Tailored bullet points with metrics
- ATS-optimized keyword coverage
- Suggestions for improvement
```

#### Critical ATS Instructions
```
CRITICAL ATS RULES:
1. üéØ Keyword density - Include ALL required skills
2. üí™ Action verbs - Start EVERY bullet with strong verb
3. üìä Quantify everything - 80%+ bullets have metrics
4. üéì Mirror job language - Use exact terminology
5. üìè Optimal length - 100-180 characters per bullet
6. üèÜ Impact formula - Action + Task + Tool + Result + Impact

BULLET POINT FORMULA:
[Action Verb] + [Specific Activity] + [with X tool/skill] + 
[achieving Y% improvement] + [resulting in $Z impact]
```

#### Token Optimization Techniques
1. **Experience Graph Condensation** - Only include relevant skills/achievements
2. **Job Description Parsing** - Extract key sections (requirements, qualifications)
3. **Structured Output** - Use JSON schema to minimize verbose responses
4. **Model Selection** - gpt-4o-mini for cost efficiency
5. **Grounding Over Scraping** - Let OpenAI fetch job posting (more efficient)

### Database Schema

#### TailoringSession Model
```python
class TailoringSession(models.Model):
    user = ForeignKey(User)
    title = CharField(max_length=255)
    status = CharField(choices=['pending', 'processing', 'completed', 'failed'])
    raw_description = TextField()  # Job description or URL
    job_snapshot = JSONField()     # Captured job data
    tailored_content = JSONField() # Generated bullets/suggestions
    ats_metadata = JSONField()     # Scores and keyword analysis
    created_at = DateTimeField()
    updated_at = DateTimeField()
```

#### ATS Metadata Structure
```json
{
  "overall_score": 87.3,
  "required_skills_score": 93.3,
  "keyword_score": 82.5,
  "preferred_skills_score": 75.0,
  "missing_required_skills": ["Kubernetes", "GraphQL"],
  "matched_keywords": ["Python", "AWS", "Django", "React"],
  "bullet_scores": [
    {"text": "...", "score": 90, "has_metric": true, "has_action_verb": true}
  ]
}
```

### Testing

#### Unit Tests
```bash
# Run all tests
python manage.py test

# Test specific module
python manage.py test tailoring.tests.test_services
```

#### Manual Testing
```bash
# Start development server
python manage.py runserver

# Start Celery worker
celery -A config worker -l info

# Create test session via admin or API
# Monitor Celery logs for processing output
```

#### Validation Checklist
- [ ] OpenAI grounding fetches job posting correctly
- [ ] ATS score calculated accurately (85%+ target)
- [ ] Required skills coverage ‚â•90%
- [ ] 80%+ bullets have quantifiable metrics
- [ ] All bullets start with action verbs
- [ ] Bullet length between 100-180 characters
- [ ] Token usage optimized (<5,000 per session)

### Best Practices

#### For Developers

1. **Always Use Grounding for URLs**
   - More reliable than custom scraping
   - Handles dynamic content automatically
   - Reduces maintenance overhead

2. **Monitor Token Usage**
   - Current average: ~4,400 tokens/session
   - Alert if sessions exceed 7,000 tokens
   - Optimize prompts when possible

3. **ATS Score Thresholds**
   - Block submissions <50% (warn user)
   - Suggest improvements for 50-84%
   - Approve 85%+ automatically

4. **Error Handling**
   - Graceful fallback if OpenAI grounding fails
   - Log all API errors for debugging
   - Provide clear user feedback

5. **Keyword Maintenance**
   - Update keyword lists quarterly
   - Add emerging technologies (e.g., new frameworks)
   - Remove deprecated terms

#### For System Administrators

**Configuration Settings:**
```python
# settings.py
OPENAI_API_KEY = env('OPENAI_API_KEY')
OPENAI_MODEL = 'gpt-4o-mini'
OPENAI_TEMPERATURE = 0.7
OPENAI_MAX_TOKENS = 2000

CELERY_BROKER_URL = env('REDIS_URL')
CELERY_RESULT_BACKEND = env('REDIS_URL')

ATS_SCORE_THRESHOLD = 85  # Target score
ATS_CRITICAL_THRESHOLD = 50  # Minimum acceptable
```

**Monitoring:**
- Track ATS score distribution (aim for 85%+ average)
- Monitor OpenAI API latency and errors
- Alert on Celery task failures
- Review token usage trends monthly

**Scaling Considerations:**
- Redis for Celery queue (handles 10K+ tasks/hour)
- PostgreSQL for session persistence
- OpenAI rate limits: 10,000 RPM (adjust if needed)
- Horizontal scaling: Add Celery workers as needed

## Troubleshooting

### Common Issues

**Issue: Low ATS Score (<70%)**
- **Cause**: Missing required skills or keywords
- **Fix**: Review "missing_required_skills" in ats_metadata, update experience graph

**Issue: OpenAI API Timeout**
- **Cause**: Large job descriptions or slow grounding
- **Fix**: Increase timeout in settings, retry task, check OpenAI status

**Issue: No Metrics in Bullets**
- **Cause**: Experience graph lacks quantifiable achievements
- **Fix**: Add metrics to achievements (%, $, time saved), re-run session

**Issue: Celery Task Stuck in 'processing'**
- **Cause**: Worker crashed or task timeout
- **Fix**: Check Celery logs, restart worker, increase task timeout

### Debug Commands

```bash
# Check Celery worker status
celery -A config inspect active

# View task details
python manage.py shell
>>> from tailoring.models import TailoringSession
>>> session = TailoringSession.objects.get(id=123)
>>> print(session.ats_metadata)

# Reprocess failed session
>>> from tailoring.tasks import process_tailoring_session
>>> process_tailoring_session.apply_async(args=[session.id])
```

## Old scripts & docs

Everything that used to live in `EXPERIENCE_FEATURE.md` is folded into this README. The legacy shell test `test_experience_service.py` has been dropped now that automated tests cover the service layer.
